{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mediapipe as mp\n",
    "from mediapipe.tasks import python\n",
    "from mediapipe.tasks.python import vision\n",
    "from IPython.display import display, Image\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "import numpy as np\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
    "\n",
    "MARGIN = 10  # pixels\n",
    "FONT_SIZE = 1\n",
    "FONT_THICKNESS = 1\n",
    "HANDEDNESS_TEXT_COLOR = (88, 205, 54) # vibrant green\n",
    "\n",
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  hand_landmarks_list = detection_result.hand_landmarks\n",
    "  handedness_list = detection_result.handedness\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected hands to visualize.\n",
    "  for idx in range(len(hand_landmarks_list)):\n",
    "    hand_landmarks = hand_landmarks_list[idx]\n",
    "    handedness = handedness_list[idx]\n",
    "\n",
    "    # Draw the hand landmarks.\n",
    "    hand_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    hand_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in hand_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      hand_landmarks_proto,\n",
    "      solutions.hands.HAND_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_hand_landmarks_style(),\n",
    "      solutions.drawing_styles.get_default_hand_connections_style())\n",
    "\n",
    "    # Get the top left corner of the detected hand's bounding box.\n",
    "    height, width, _ = annotated_image.shape\n",
    "    x_coordinates = [landmark.x for landmark in hand_landmarks]\n",
    "    y_coordinates = [landmark.y for landmark in hand_landmarks]\n",
    "    text_x = int(min(x_coordinates) * width)\n",
    "    text_y = int(min(y_coordinates) * height) - MARGIN\n",
    "\n",
    "    # Draw handedness (left or right hand) on the image.\n",
    "    cv2.putText(annotated_image, f\"{handedness[0].category_name}\",\n",
    "                (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
    "                FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
    "\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from IPython.display import display\n",
    "\n",
    "image_path = '/Users/polo/Dev/Datasets/Gesture_Dataset/1/paper/images/Paper_1.jpg'\n",
    "# image = mp.Image.create_from_file(image_path)\n",
    "# imagecv2 = cv2.imread(image_path)\n",
    "image = Image.open(image_path)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1725920359.734486 7573217 gl_context.cc:357] GL version: 2.1 (2.1 ATI-5.5.17), renderer: AMD Radeon Pro 5300M OpenGL Engine\n",
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n",
      "W0000 00:00:1725920359.775045 7612567 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1725920359.802380 7612574 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n",
      "W0000 00:00:1725920360.043748 7612575 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n",
      "/Users/polo/.pyenv/versions/GoogleAI/lib/python3.12/site-packages/google/protobuf/symbol_database.py:55: UserWarning: SymbolDatabase.GetPrototype() is deprecated. Please use message_factory.GetMessageClass() instead. SymbolDatabase.GetPrototype() will be removed soon.\n",
      "  warnings.warn('SymbolDatabase.GetPrototype() is deprecated. Please '\n"
     ]
    }
   ],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "HandLandmarker = mp.tasks.vision.HandLandmarker\n",
    "HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "# Create a hand landmarker instance with the image mode:\n",
    "options = HandLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
    "    running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "\n",
    "landmarker = HandLandmarker.create_from_options(options)\n",
    "hand_landmarks = landmarker.detect(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[NormalizedLandmark(x=0.44862818717956543, y=0.18581345677375793, z=9.573888064551284e-07, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.342389315366745, y=0.22779536247253418, z=-0.12375405430793762, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.2837750017642975, y=0.3483584523200989, z=-0.17188504338264465, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.263131707906723, y=0.46443861722946167, z=-0.20348414778709412, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.27534663677215576, y=0.5901146531105042, z=-0.23413677513599396, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.3434586524963379, y=0.5337473750114441, z=-0.07921560108661652, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.34071341156959534, y=0.6932615637779236, z=-0.1109757125377655, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.3386344909667969, y=0.7942944169044495, z=-0.14261417090892792, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.34550508856773376, y=0.8759201765060425, z=-0.1666976362466812, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.41295382380485535, y=0.5409470796585083, z=-0.04358655959367752, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.40758541226387024, y=0.726028561592102, z=-0.06444469094276428, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.4045043885707855, y=0.8389442563056946, z=-0.09552499651908875, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.4025691747665405, y=0.9306618571281433, z=-0.1227908730506897, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.46967506408691406, y=0.5268227458000183, z=-0.022809766232967377, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.4713645279407501, y=0.6857122778892517, z=-0.04939651861786842, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.46680331230163574, y=0.7879743576049805, z=-0.08636325597763062, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.4626835882663727, y=0.8742159605026245, z=-0.11561903357505798, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.5167813301086426, y=0.5019091963768005, z=-0.014400732703506947, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.5213133096694946, y=0.6179437637329102, z=-0.04424353688955307, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.5215144157409668, y=0.6944416761398315, z=-0.07365768402814865, visibility=0.0, presence=0.0),\n",
       "  NormalizedLandmark(x=0.5151450037956238, y=0.7614489197731018, z=-0.09887763112783432, visibility=0.0, presence=0.0)]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hand_landmarks.hand_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "tuple index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mdraw_landmarks_on_image\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhand_landmarks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[2], line 23\u001b[0m, in \u001b[0;36mdraw_landmarks_on_image\u001b[0;34m(rgb_image, detection_result)\u001b[0m\n\u001b[1;32m     19\u001b[0m hand_landmarks_proto \u001b[38;5;241m=\u001b[39m landmark_pb2\u001b[38;5;241m.\u001b[39mNormalizedLandmarkList()\n\u001b[1;32m     20\u001b[0m hand_landmarks_proto\u001b[38;5;241m.\u001b[39mlandmark\u001b[38;5;241m.\u001b[39mextend([\n\u001b[1;32m     21\u001b[0m   landmark_pb2\u001b[38;5;241m.\u001b[39mNormalizedLandmark(x\u001b[38;5;241m=\u001b[39mlandmark\u001b[38;5;241m.\u001b[39mx, y\u001b[38;5;241m=\u001b[39mlandmark\u001b[38;5;241m.\u001b[39my, z\u001b[38;5;241m=\u001b[39mlandmark\u001b[38;5;241m.\u001b[39mz) \u001b[38;5;28;01mfor\u001b[39;00m landmark \u001b[38;5;129;01min\u001b[39;00m hand_landmarks\n\u001b[1;32m     22\u001b[0m ])\n\u001b[0;32m---> 23\u001b[0m \u001b[43msolutions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrawing_utils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw_landmarks\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m  \u001b[49m\u001b[43mannotated_image\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m  \u001b[49m\u001b[43mhand_landmarks_proto\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[43m  \u001b[49m\u001b[43msolutions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhands\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mHAND_CONNECTIONS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     27\u001b[0m \u001b[43m  \u001b[49m\u001b[43msolutions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrawing_styles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_hand_landmarks_style\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m  \u001b[49m\u001b[43msolutions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrawing_styles\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_default_hand_connections_style\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Get the top left corner of the detected hand's bounding box.\u001b[39;00m\n\u001b[1;32m     31\u001b[0m height, width, _ \u001b[38;5;241m=\u001b[39m annotated_image\u001b[38;5;241m.\u001b[39mshape\n",
      "File \u001b[0;32m~/.pyenv/versions/GoogleAI/lib/python3.12/site-packages/mediapipe/python/solutions/drawing_utils.py:157\u001b[0m, in \u001b[0;36mdraw_landmarks\u001b[0;34m(image, landmark_list, connections, landmark_drawing_spec, connection_drawing_spec, is_drawing_landmarks)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m landmark_list:\n\u001b[1;32m    156\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[0;32m--> 157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m!=\u001b[39m _BGR_CHANNELS:\n\u001b[1;32m    158\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInput image must contain three channel bgr data.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    159\u001b[0m image_rows, image_cols, _ \u001b[38;5;241m=\u001b[39m image\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
     ]
    }
   ],
   "source": [
    "draw_landmarks_on_image(image, hand_landmarks)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GoogleAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
